# ğŸ¤– AI Recipe Assistant (FastAPI + Azure SDK)

This project implements a simple backend using **FastAPI** and the **Azure AI SDK (Python)** to power an AI chat assistant that returns recipes based on user input. The system is designed to connect with a mobile application built using **Flutter (Dart)**.

---

## ğŸ“Œ Overview

- **Purpose**: Receive user input (like "I want to eat chicken") and return AI-generated recipe suggestions.
- **AI Model**: Azure OpenAI GPT via `azure-ai-inference` SDK.
- **Frontend**: A Flutter mobile app sending user input.
- **Backend**: Python (FastAPI), which connects to Azure AI services.
- **Communication**: FastAPI exposes a POST endpoint at `/chat/`.

---

## ğŸ§  SDK Client vs REST Client

Azure AI services can be accessed in two main ways:

| Feature             | **SDK Client** (Used Here)                   | **REST Client**                           |
|---------------------|----------------------------------------------|-------------------------------------------|
| Code Abstraction    | High â€“ uses pre-built classes/methods        | Low â€“ manual HTTP requests                |
| Complexity          | Easy to use                                  | More verbose and error-prone              |
| Performance         | Comparable, but SDK manages retries/errors   | Full control, but more setup              |
| Language Support    | Python, C#, Java (via official SDKs)         | Any language supporting HTTP              |
| Authentication      | Built-in (`AzureKeyCredential`)              | Manual (set headers, keys)                |

### ğŸ”¹ We used: **SDK Client**  
The SDK provides a simpler, cleaner way to interact with Azure AIâ€”ideal for Python development and prototyping.

---

## ğŸ› ï¸ How SDK Works (Simple Terms)

With SDK, you donâ€™t need to construct raw HTTP requests. Instead, you use classes like `ChatCompletionsClient`, `UserMessage`, and `SystemMessage`.

The SDK handles:
- Authentication
- Message formatting
- Token limits
- Retry logic
- Response parsing

---

## ğŸ” Sequence of Execution

Below is a step-by-step breakdown of how the system works from end to end:

### 1. âœ… Mobile App Sends Input

The Flutter app sends a POST request to the FastAPI server:

```
POST http://localhost:8000/chat/
Content-Type: application/json

{
  "user_input": "I want to eat chicken"
}
```

---

### 2. âš™ï¸ FastAPI Receives the Request

Inside `main.py`, the `/chat/` endpoint parses this using a Pydantic model:

```python
class ChatRequest(BaseModel):
    user_input: str
```

---

### 3. ğŸ’¬ Message Sent to Azure AI

The SDK sends a message to Azure OpenAI using the `ChatCompletionsClient`:

```python
response = client.complete(
    messages=[
        SystemMessage(content="You are a helpful assistant. Respond in English..."),
        UserMessage(content=request.user_input)
    ],
    model=model_name,
    max_tokens=2048
)
```

**Note**: `SystemMessage` is used to guide the AIâ€™s tone and format.

---

### 4. ğŸ§¹ Response Cleanup (Remove Internal Markup)

The Azure model sometimes includes internal tags like `<think>`. We clean them:

```python
final_response = response.choices[0].message.content.strip()
final_response = final_response.split("</think>\n\n")[-1]
```

---

### 5. ğŸ” Return Response to Mobile App

The FastAPI app returns a JSON response back to Flutter:

```json
{
  "response": "Here are 3 simple chicken recipes..."
}
```

---

## ğŸ“ Project Structure

```
project/
â”‚
â”œâ”€â”€ main.py               # Main FastAPI app
â”œâ”€â”€ config.py             # Contains API key, endpoint, model
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # This documentation
```

---

## ğŸ” config.py Example

```python
class Config:
    ENDPOINT = "https://<your-endpoint>.openai.azure.com"
    API_KEY = "your-azure-api-key"
    MODEL_NAME = "gpt-35-turbo"
```

---

## ğŸ“¦ requirements.txt

```text
fastapi
uvicorn
azure-ai-inference
python-dotenv
pydantic
```

---

## âœ… Conclusion

- This project uses **SDK Client** for fast, clean integration with Azure AI.
- It is easier to maintain and extend than manual REST-based implementations.
- The FastAPI backend acts as a bridge between the AI model and a Flutter frontend.
- Markdown formatting is supported in responses, and system prompts control the output style.

---

## ğŸ”„ Future Enhancements

- Add support for image input (via Azure Vision API)
- Use REST client for advanced customization
- Add user authentication and role management
- Handle streaming responses (real-time AI typing)

---

ğŸ“§ **Developed by:**  
Ali Arabi | Machine Learning Engineer. 
ğŸ“© **Email:** aliarabimak@gmail.com  
ğŸ”— **LinkedIn:** [Ali Arabi](https://www.linkedin.com/in/aliarabi55/)

